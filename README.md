# Ограничение генерации LLM на уровне логитов

Токен-маскинг и логит-редактирование для запрета нежелательных слов

> Research Proposal для моей дипломной работы

## Теория

> Прежде чем писать работу, нужно найти источники. Прежде чем искать источники, нужно понять о чём я буду писать

### Что такое логиты

**Логиты** - неотнормированные вероятности токенов, выход из последнего слоя нейросети перед тем, как выбрать следующий токен.

По сути логит - оценка *желательности* токена в текущем контексте.

Логит - **вектор чисел**, в котором каждому токену из словаря модели вроде `the`, `cat`, `##ing`, `<|endoftext|>`, соответствует одно число.

Например:

```python
# длина списка = размер словаря модели, обычно более 50к
logits = [2.5, -1.2, .0, 4.7, ...]
```

#### Логиты и вероятность

Логиты проходят через **softmax**-функцию, которая превращает их в вероятности:

```python
probs = softmax(logits)
```

Чем выше логит, тем выше вероятность токены. Логиты определяют **распределение вероятностей** для следующего токена

Рассмотрим на примере:

```python
logits = torch.tensor([0.5, 2.0, 1.0])
probs = torch.softmax(logits, dim=-1)

# probs = [0.14, 0.63, 0.23]
```

Токен с логитом `2.0` будет выбран с вероятностью 63%, а `0.5` - с 14%

#### Логиты в генерации

Генерация LLM - это выбор следующего токена на основе логитов:

1. Модель прочитала строку `I want to`
2. Выдала логиты для всех токенов
3. Из логитов сделала вероятности с помощью *softmax*
4. По вероятностям либо выбирает случайно, либо берёт самый вероятный вариант

Если мы устанавливает логит в `-inf`, то фактически **запрещаем токен** - его вероятность становится $0$ => он не появится в генерации

### Откуда модель берёт логиты?

Модель вычисляет логиты на основе входного текста, через свои внутренние слои.

Например, я подаю на вход:

```python
 input_ids = tokenizer('Hello, I love you!', return_tensors='pt').input_ids

>>> input_ids
tensor([[15496, 11, 314, 1842, 345, 0]])
 ```
